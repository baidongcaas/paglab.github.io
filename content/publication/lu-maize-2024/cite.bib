@article{lu_maize_2024,
 abstract = {In recent years, computer vision (CV) has made enormous progress and is providing great possibilities in analyzing images for object detection, especially with the application of machine learning (ML). Unmanned Aerial Vehicle (UAV) based high-resolution images allow to apply CV and ML methods for the detection of plants or their organs of interest. Thus, this study presents a practical workflow based on the You Only Look Once version 5 (YOLOv5) and UAV images to detect maize plants for counting their numbers in contrasting development stages, including the application of a semi-auto-labeling method based on the Segment Anything Model (SAM) to reduce the burden of labeling. Results showed that the trained model achieved a mean average precision (mAP@0.5) of 0.828 and 0.863 for the 3-leaf stage and 7-leaf stage, respectively. YOLOv5 achieved the best performance under the conditions of overgrown weeds, leaf occlusion, and blurry images, suggesting that YOLOv5 plays a practical role in obtaining excellent performance under realistic field conditions. Furthermore, introducing image-rotation augmentation and low noise weight enhanced model accuracy, with an increase of 0.024 and 0.016 mAP@0.5, respectively, compared to the original model of the 3-leaf stage. This work provides a practical reference for applying lightweight ML and deep learning methods to UAV images for automated object detection and characterization of plant growth under realistic environments.},
 author = {Lu, Chenghao and Nnadozie, Emmanuel and Camenzind, Moritz Paul and Hu, Yuncai and Yu, Kang},
 copyright = {All rights reserved},
 doi = {10.3389/fpls.2023.1274813},
 file = {Full Text PDF:/Users/kang/Zotero/storage/EHILRS3K/Lu et al. - 2024 - Maize plant detection using UAV-based RGB imaging .pdf:application/pdf},
 issn = {1664-462X},
 journal = {Frontiers in Plant Science},
 pages = {1274813},
 title = {Maize plant detection using UAV-based RGB imaging and YOLOv5},
 url = {https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2023.1274813},
 urldate = {2024-02-25},
 volume = {14},
 year = {2024}
}

